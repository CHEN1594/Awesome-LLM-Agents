<div align="center">
  <h2><b> Awesome-LLM-Agents </b></h2>
</div>

<div align="center">
![](https://img.shields.io/github/stars/CHEN1594/Awesome-LLM-Agents?color=yellow)
![](https://img.shields.io/github/last-commit/CHEN1594/Awesome-LLM-Agents?color=green)
![](https://img.shields.io/badge/PRs-Welcome-blue)
</div>
## Full list
---

### Quick Links
  - [Agent Tool Use](#agent-tool-use)
    - [Search Tool](#search-tool)
    - [Image Manipulation (Crop/Rotate)](#image-manipulation-croprotate)
    - [Code Tool](#code-tool)
    - [Other Tools](#other-tools)
    - [Dynamic Tool Creation (Sandbox)](#dynamic-tool-creation-sandbox)
  - [GUI Operation](#gui-operation)
  - [Evaluation](#evaluation)
  - [Survey](#survey)
    - [Tool](#tool)
    - [GUI](#gui)
  - [Background](#background)


### Agent Tool Use
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT.svg?style=social&label=Star)](https://github.com/Liuziyu77/Visual-RFT) [![Publish](https://img.shields.io/badge/Conference-ICCV_2025-blue)]()<br>[Visual Agentic Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.14246v1) <br> Ziyu Liu, Yuhang Zang, Yushan Zou, Zijian Liang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14246v1/x2.png"> |[Github](https://github.com/Liuziyu77/Visual-RFT) <br> [Paper](https://arxiv.org/abs/2505.14246v1)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/zhaochen0110/OpenThinkIMG.svg?style=social&label=Star)](https://github.com/zhaochen0110/OpenThinkIMG)<br>[OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning](https://arxiv.org/abs/2505.08617v2) <br> Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu, Juntao Li, Xiaoye Qu, Yu Cheng |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08617v2/x1.png"> |[Github](https://github.com/zhaochen0110/OpenThinkIMG) <br> [Paper](https://arxiv.org/abs/2505.08617v2)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/RUC-NLPIR/WebThinker.svg?style=social&label=Star)](https://github.com/RUC-NLPIR/WebThinker)<br>[WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/abs/2504.21776) <br> Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou |<img width="1002" alt="image" src="https://github.com/RUC-NLPIR/WebThinker/raw/main/figures/framework.png"> |[Github](https://github.com/RUC-NLPIR/WebThinker) <br> [Paper](https://arxiv.org/abs/2504.21776)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/agents-x-project/PyVision.svg?style=social&label=Star)](https://github.com/agents-x-project/PyVision)<br>[PyVision: Agentic Vision with Dynamic Tooling](https://arxiv.org/abs/2507.07998) <br> Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei |<img width="1002" alt="image" src="figures/PyVision.png"> |[Github](https://github.com/agents-x-project/PyVision) <br> [Paper](https://arxiv.org/abs/2507.07998)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/Alibaba-NLP/WebAgent.svg?style=social&label=Star)](https://github.com/Alibaba-NLP/WebAgent)<br>[WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592) <br> Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, Weizhou Shen, Junkai Zhang, Dingchu Zhang, Xixi Wu, Yong Jiang, Ming Yan, Pengjun Xie, Fei Huang, Jingren Zhou |<img width="1002" alt="image" src="figures/WebSailor.png"> |[Github](https://github.com/Alibaba-NLP/WebAgent) <br> [Paper](https://arxiv.org/abs/2507.02592)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/sunnynexus/Search-o1.svg?style=social&label=Star)](https://github.com/sunnynexus/Search-o1)<br>[Search-o1: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366) <br> Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou |<img width="1002" alt="image" src="https://arxiv.org/html/2501.05366v1/x2.png"> |[Github](https://github.com/sunnynexus/Search-o1) <br> [Paper](https://arxiv.org/abs/2501.05366)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/multimodal-search-r1.svg?style=social&label=Star)](https://github.com/EvolvingLMMs-Lab/multimodal-search-r1)<br>[MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670) <br> Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, Ziwei Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.20670v1/x1.png"> |[Github](https://github.com/EvolvingLMMs-Lab/multimodal-search-r1) <br> [Paper](https://arxiv.org/abs/2506.20670)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/yhy-2000/VideoDeepResearch.svg?style=social&label=Star)](https://github.com/yhy-2000/VideoDeepResearch)<br>[VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821) <br> Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Ji-Rong Wen, Zhicheng Dou |<img width="1002" alt="image" src="https://arxiv.org/html/2506.10821v2/x2.png"> |[Github](https://github.com/yhy-2000/VideoDeepResearch) <br> [Paper](https://arxiv.org/abs/2506.10821)| [//]: #07/14
#### Benchmark
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/CaraJ7/MMSearch.svg?style=social&label=Star)](https://github.com/CaraJ7/MMSearch) [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[MMSearch: Benchmarking the Potential of Large Models as Multi-modal Search Engines](https://arxiv.org/abs/2409.12959v2) <br> Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanmin Wu, Jiayi Lei, Pengshuo Qiu, Pan Lu, Zehui Chen, Chaoyou Fu, Guanglu Song, Peng Gao, Yu Liu, Chunyuan Li, Hongsheng Li |<img width="1002" alt="image" src="https://arxiv.org/html/2409.12959v2/x1.png"> |[Github](https://github.com/CaraJ7/MMSearch) <br> [Paper](https://arxiv.org/abs/2409.12959v2)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/osu-nlp-group/mind2web2.svg?style=social&label=Star)](https://github.com/osu-nlp-group/mind2web2)<br>[Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506) <br> Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su |<img width="1002" alt="image" src="https://github.com/OSU-NLP-Group/Mind2Web-2/raw/main/assets/mind2web2_overview.jpg"> |[Github](https://github.com/osu-nlp-group/mind2web2) <br> [Paper](https://arxiv.org/abs/2506.21506)| [//]: #07/14

#### Search Tool

#### Image Manipulation (Crop/Rotate)

#### Code Tool

#### Other Tools

#### Dynamic Tool Creation (Sandbox)

### GUI Operation
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/Yan98/GTA1.svg?style=social&label=Star)](https://github.com/Yan98/GTA1)<br>[GTA1: GUI Test-time Scaling Agent](https://www.arxiv.org/abs/2507.05791) <br> Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2507.05791v3/x2.png"> |[Github](https://github.com/Yan98/GTA1) <br> [Paper](https://www.arxiv.org/abs/2507.05791)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/showlab/ShowUI.svg?style=social&label=Star)](https://github.com/showlab/ShowUI) [![Publish](https://img.shields.io/badge/Conference-CVPR_2025-blue)]()<br>[ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://arxiv.org/abs/2411.17465) <br> Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou |<img width="1002" alt="image" src="https://arxiv.org/html/2411.17465v1/x4.png"> |[Github](https://github.com/showlab/ShowUI) <br> [Paper](https://arxiv.org/abs/2411.17465)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/TencentQQGYLab/AppAgent.svg?style=social&label=Star)](https://github.com/TencentQQGYLab/AppAgent) [![Publish](https://img.shields.io/badge/Conference-CHI_2025-blue)]()<br>[AppAgent: Multimodal Agents as Smartphone Users](https://arxiv.org/abs/2312.13771) <br> Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, Gang Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2312.13771v2/x2.png"> |[Github](https://github.com/TencentQQGYLab/AppAgent) <br> [Paper](https://arxiv.org/abs/2312.13771)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/JiuTian-VL/Mirage-1.svg?style=social&label=Star)](https://github.com/JiuTian-VL/Mirage-1)<br>[Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387) <br> Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie |<img width="1002" alt="image" src="https://arxiv.org/html/2506.10387v1/x2.png"> |[Github](https://github.com/JiuTian-VL/Mirage-1) <br> [Paper](https://arxiv.org/abs/2506.10387)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/sunblaze-ucb/AgentSynth.svg?style=social&label=Star)](https://github.com/sunblaze-ucb/AgentSynth)<br>[AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/abs/2506.14205) <br> Jingxu Xie, Dylan Xu, Xuandong Zhao, Dawn Song |<img width="1002" alt="image" src="figures/AgentSynth.png"> |[Github](https://github.com/sunblaze-ucb/AgentSynth) <br> [Paper](https://arxiv.org/abs/2506.14205)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/X-PLUG/MobileAgent.svg?style=social&label=Star)](https://github.com/X-PLUG/MobileAgent)<br>[Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation](https://arxiv.org/abs/2506.04614) <br> Yuyang Wanyan, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Jiabo Ye, Yutong Kou, Ming Yan, Fei Huang, Xiaoshan Yang, Weiming Dong, Changsheng Xu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.04614v1/x2.png"> |[Github](https://github.com/X-PLUG/MobileAgent) <br> [Paper](https://arxiv.org/abs/2506.04614)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/penghao-wu/GUI_Reflection.svg?style=social&label=Star)](https://github.com/penghao-wu/GUI_Reflection)<br>[GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior](https://arxiv.org/abs/2506.08012) <br> Penghao Wu, Shengnan Ma, Bo Wang, Jiaheng Yu, Lewei Lu, Ziwei Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.08012v1/x2.png"> |[Github](https://github.com/penghao-wu/GUI_Reflection) <br> [Paper](https://arxiv.org/abs/2506.08012)| [//]: #07/13
### Evaluation

### Survey
#### Tool
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/jingyi0000/VLM_survey.svg?style=social&label=Star)](https://github.com/jingyi0000/VLM_survey) [![Publish](https://img.shields.io/badge/Conference-TPAMI_2024-blue)]()<br>[Vision-Language Models for Vision Tasks: A Survey](https://arxiv.org/abs/2304.00685) <br> Jingyi Zhang, Jiaxing Huang, Sheng Jin, Shijian Lu |<img width="1002" alt="image" src="https://arxiv.org/html/2304.00685v2/x4.png"> |[Github](https://github.com/jingyi0000/VLM_survey) <br> [Paper](https://arxiv.org/abs/2304.00685)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/quchangle1/LLM-Tool-Survey.svg?style=social&label=Star)](https://github.com/quchangle1/LLM-Tool-Survey) [![Publish](https://img.shields.io/badge/Conference-FCS_2025-blue)]()<br>[Tool Learning with Large Language Models: A Survey](https://arxiv.org/abs/2405.17935v1) <br> Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen |<img width="1002" alt="image" src="https://arxiv.org/html/2405.17935v1/x2.png"> |[Github](https://github.com/quchangle1/LLM-Tool-Survey) <br> [Paper](https://arxiv.org/abs/2405.17935v1)| [//]: #07/14
|[What Are Tools Anyway? A Survey from the Language Model Perspective](https://arxiv.org/abs/2403.15452) <br> Zhiruo Wang, Zhoujun Cheng, Hao Zhu, Daniel Fried, Graham Neubig |<img width="1002" alt="image" src="https://arxiv.org/html/2403.15452v1/x1.png"> |[Paper](https://arxiv.org/abs/2403.15452)| [//]: #07/14
#### GUI
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[GUI Agents with Foundation Models: A Comprehensive Survey](https://arxiv.org/abs/2411.04890) <br> Shuai Wang, Weiwen Liu, Jingxuan Chen, Yuqi Zhou, Weinan Gan, Xingshan Zeng, Yuhan Che, Shuai Yu, Xinlong Hao, Kun Shao, Bin Wang, Chuhan Wu, Yasheng Wang, Ruiming Tang, Jianye Hao |<img width="1002" alt="image" src="https://arxiv.org/html/2411.04890v2/x2.png"> |[Paper](https://arxiv.org/abs/2411.04890)| [//]: #07/14
### Background

## Acknowledgement

This repository is inspired by [Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM/) and [Awesome-Efficient-Reasoning-Models
](https://github.com/fscdc/Awesome-Efficient-Reasoning-Models)