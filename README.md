<div align="center">
  <h2><b> Awesome-LLM-Agents </b></h2>
</div>

<div align="center">
  <img src="https://img.shields.io/github/stars/CHEN1594/Awesome-LLM-Agents?color=yellow" alt="GitHub Stars">
  <img src="https://img.shields.io/github/last-commit/CHEN1594/Awesome-LLM-Agents?color=green" alt="Last Commit">
  <img src="https://img.shields.io/badge/PRs-Welcome-blue" alt="PRs Welcome">
</div>

## Full list

### Quick Links
  - [Agent Tool Use](#agent-tool-use)
  - [GUI Operation](#gui-operation)
  - [Data Generation for Agent Training](#data-generation-for-agent-training)
  - [Evaluation](#evaluation)
  - [Dataset](#dataset)
  - [Survey](#survey)
    - [Background](#background)
    - [Tool](#tool)
    - [GUI](#gui)
  - [Background](#background)
  - [Domain-Specific Agents](#domain-specific-agents)



### Agent Tool Use
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/xfey/MCP-Zero.svg?style=social&label=Star)](https://github.com/xfey/MCP-Zero)<br>[MCP-Zero: Active Tool Discovery for Autonomous LLM Agents](https://arxiv.org/abs/2506.01056) <br> Xiang Fei, Xiawu Zheng, Hao Feng |<img width="1002" alt="image" src="https://github.com/xfey/MCP-Zero/raw/master/assets/fig1.png"> |[Github](https://github.com/xfey/MCP-Zero) <br> [Paper](https://arxiv.org/abs/2506.01056)| [//]: #07/17
|[ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph](https://arxiv.org/abs/2403.00839) <br> Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, Dongkuan Xu |<img width="1002" alt="image" src="figures/ToolNet.png"> |[Paper](https://arxiv.org/abs/2403.00839)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/SPORT-Agents/SPORT-Agents.svg?style=social&label=Star)](https://github.com/SPORT-Agents/SPORT-Agents)<br>[Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning](https://arxiv.org/abs/2504.21561) <br> Pengxiang Li, Zhi Gao, Bofei Zhang, Yapeng Mi, Xiaojian Ma, Chenrui Shi, Tao Yuan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li |<img width="1002" alt="image" src="https://arxiv.org/html/2504.21561v3/x1.png"> |[Github](https://github.com/SPORT-Agents/SPORT-Agents) <br> [Paper](https://arxiv.org/abs/2504.21561)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/NVlabs/Tool-N1.svg?style=social&label=Star)](https://github.com/NVlabs/Tool-N1)<br>[Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning](https://arxiv.org/abs/2505.00024) <br> Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu |<img width="1002" alt="image" src="https://github.com/NVlabs/Tool-N1/raw/master/assets/overview.png"> |[Github](https://github.com/NVlabs/Tool-N1) <br> [Paper](https://arxiv.org/abs/2505.00024)| [//]: #07/17
| [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[StepTool: Enhancing Multi-Step Tool Usage in LLMs through Step-Grained Reinforcement Learning](https://arxiv.org/abs/2410.07745) <br> Yuanqing Yu, Zhefan Wang, Weizhi Ma, Shuai Wang, Chuhan Wu, Zhiqiang Guo, Min Zhang |<img width="1002" alt="image" src="figures/StepTool.png"> |[Paper](https://arxiv.org/abs/2410.07745)| [//]: #07/17
|[OTC: Optimal Tool Calls via Reinforcement Learning](https://arxiv.org/abs/2504.14870v1) <br> Hongru Wang, Cheng Qian, Wanjun Zhong, Xiusi Chen, Jiahao Qiu, Shijue Huang, Bowen Jin, Mengdi Wang, Kam-Fai Wong, Heng Ji |<img width="1002" alt="image" src="https://arxiv.org/html/2504.14870v1/x1.png"> |[Paper](https://arxiv.org/abs/2504.14870v1)| [//]: #07/16
|[![Star](https://img.shields.io/github/stars/sjtu-sai-agents/X-Master.svg?style=social&label=Star)](https://github.com/sjtu-sai-agents/X-Master)<br>[SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?](https://arxiv.org/abs/2507.05241v2) <br> Jingyi Chai, Shuo Tang, Rui Ye, Yuwen Du, Xinyu Zhu, Mengcheng Zhou, Yanfeng Wang, Weinan E, Yuzhi Zhang, Linfeng Zhang, Siheng Chen |<img width="1002" alt="image" src="https://arxiv.org/html/2507.05241v2/x1.png"> |[Github](https://github.com/sjtu-sai-agents/X-Master) <br> [Paper](https://arxiv.org/abs/2507.05241v2)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/Liuziyu77/Visual-RFT.svg?style=social&label=Star)](https://github.com/Liuziyu77/Visual-RFT) [![Publish](https://img.shields.io/badge/Conference-ICCV_2025-blue)]()<br>[Visual Agentic Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.14246v1) <br> Ziyu Liu, Yuhang Zang, Yushan Zou, Zijian Liang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang |<img width="1002" alt="image" src="https://arxiv.org/html/2505.14246v1/x2.png"> |[Github](https://github.com/Liuziyu77/Visual-RFT) <br> [Paper](https://arxiv.org/abs/2505.14246v1)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/zhaochen0110/OpenThinkIMG.svg?style=social&label=Star)](https://github.com/zhaochen0110/OpenThinkIMG)<br>[OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning](https://arxiv.org/abs/2505.08617v2) <br> Zhaochen Su, Linjie Li, Mingyang Song, Yunzhuo Hao, Zhengyuan Yang, Jun Zhang, Guanjie Chen, Jiawei Gu, Juntao Li, Xiaoye Qu, Yu Cheng |<img width="1002" alt="image" src="https://arxiv.org/html/2505.08617v2/x1.png"> |[Github](https://github.com/zhaochen0110/OpenThinkIMG) <br> [Paper](https://arxiv.org/abs/2505.08617v2)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/RUC-NLPIR/WebThinker.svg?style=social&label=Star)](https://github.com/RUC-NLPIR/WebThinker)<br>[WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/abs/2504.21776) <br> Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, Zhicheng Dou |<img width="1002" alt="image" src="https://github.com/RUC-NLPIR/WebThinker/raw/main/figures/framework.png"> |[Github](https://github.com/RUC-NLPIR/WebThinker) <br> [Paper](https://arxiv.org/abs/2504.21776)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/agents-x-project/PyVision.svg?style=social&label=Star)](https://github.com/agents-x-project/PyVision)<br>[PyVision: Agentic Vision with Dynamic Tooling](https://arxiv.org/abs/2507.07998) <br> Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei |<img width="1002" alt="image" src="figures/PyVision.png"> |[Github](https://github.com/agents-x-project/PyVision) <br> [Paper](https://arxiv.org/abs/2507.07998)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/Alibaba-NLP/WebAgent.svg?style=social&label=Star)](https://github.com/Alibaba-NLP/WebAgent)<br>[WebSailor: Navigating Super-human Reasoning for Web Agent](https://arxiv.org/abs/2507.02592) <br> Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, Weizhou Shen, Junkai Zhang, Dingchu Zhang, Xixi Wu, Yong Jiang, Ming Yan, Pengjun Xie, Fei Huang, Jingren Zhou |<img width="1002" alt="image" src="figures/WebSailor.png"> |[Github](https://github.com/Alibaba-NLP/WebAgent) <br> [Paper](https://arxiv.org/abs/2507.02592)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/sunnynexus/Search-o1.svg?style=social&label=Star)](https://github.com/sunnynexus/Search-o1)<br>[Search-o1: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366) <br> Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou |<img width="1002" alt="image" src="https://arxiv.org/html/2501.05366v1/x2.png"> |[Github](https://github.com/sunnynexus/Search-o1) <br> [Paper](https://arxiv.org/abs/2501.05366)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/multimodal-search-r1.svg?style=social&label=Star)](https://github.com/EvolvingLMMs-Lab/multimodal-search-r1)<br>[MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670) <br> Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, Ziwei Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.20670v1/x1.png"> |[Github](https://github.com/EvolvingLMMs-Lab/multimodal-search-r1) <br> [Paper](https://arxiv.org/abs/2506.20670)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/yhy-2000/VideoDeepResearch.svg?style=social&label=Star)](https://github.com/yhy-2000/VideoDeepResearch)<br>[VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821) <br> Huaying Yuan, Zheng Liu, Junjie Zhou, Hongjin Qian, Ji-Rong Wen, Zhicheng Dou |<img width="1002" alt="image" src="https://arxiv.org/html/2506.10821v2/x2.png"> |[Github](https://github.com/yhy-2000/VideoDeepResearch) <br> [Paper](https://arxiv.org/abs/2506.10821)| [//]: #07/14
### GUI Operation
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/microsoft/GUI-Actor.svg?style=social&label=Star)](https://github.com/microsoft/GUI-Actor)<br>[GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://arxiv.org/abs/2506.03143) <br> Qianhui Wu, Kanzhi Cheng, Rui Yang, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng, Bo Qiao, Reuben Tan, Si Qin, Lars Liden, Qingwei Lin, Huan Zhang, Tong Zhang, Jianbing Zhang, Dongmei Zhang, Jianfeng Gao |<img width="1002" alt="image" src="https://microsoft.github.io/GUI-Actor/static/images/actor_model_illustration.png"> |[Github](https://github.com/microsoft/GUI-Actor) <br> [Paper](https://arxiv.org/abs/2506.03143)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/Yan98/GTA1.svg?style=social&label=Star)](https://github.com/Yan98/GTA1)<br>[GTA1: GUI Test-time Scaling Agent](https://www.arxiv.org/abs/2507.05791) <br> Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li |<img width="1002" alt="image" src="https://arxiv.org/html/2507.05791v3/x2.png"> |[Github](https://github.com/Yan98/GTA1) <br> [Paper](https://www.arxiv.org/abs/2507.05791)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/showlab/ShowUI.svg?style=social&label=Star)](https://github.com/showlab/ShowUI) [![Publish](https://img.shields.io/badge/Conference-CVPR_2025-blue)]()<br>[ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://arxiv.org/abs/2411.17465) <br> Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou |<img width="1002" alt="image" src="https://arxiv.org/html/2411.17465v1/x4.png"> |[Github](https://github.com/showlab/ShowUI) <br> [Paper](https://arxiv.org/abs/2411.17465)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/TencentQQGYLab/AppAgent.svg?style=social&label=Star)](https://github.com/TencentQQGYLab/AppAgent) [![Publish](https://img.shields.io/badge/Conference-CHI_2025-blue)]()<br>[AppAgent: Multimodal Agents as Smartphone Users](https://arxiv.org/abs/2312.13771) <br> Chi Zhang, Zhao Yang, Jiaxuan Liu, Yucheng Han, Xin Chen, Zebiao Huang, Bin Fu, Gang Yu |<img width="1002" alt="image" src="https://arxiv.org/html/2312.13771v2/x2.png"> |[Github](https://github.com/TencentQQGYLab/AppAgent) <br> [Paper](https://arxiv.org/abs/2312.13771)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/JiuTian-VL/Mirage-1.svg?style=social&label=Star)](https://github.com/JiuTian-VL/Mirage-1)<br>[Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387) <br> Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie |<img width="1002" alt="image" src="https://arxiv.org/html/2506.10387v1/x2.png"> |[Github](https://github.com/JiuTian-VL/Mirage-1) <br> [Paper](https://arxiv.org/abs/2506.10387)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/X-PLUG/MobileAgent.svg?style=social&label=Star)](https://github.com/X-PLUG/MobileAgent)<br>[Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation](https://arxiv.org/abs/2506.04614) <br> Yuyang Wanyan, Xi Zhang, Haiyang Xu, Haowei Liu, Junyang Wang, Jiabo Ye, Yutong Kou, Ming Yan, Fei Huang, Xiaoshan Yang, Weiming Dong, Changsheng Xu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.04614v1/x2.png"> |[Github](https://github.com/X-PLUG/MobileAgent) <br> [Paper](https://arxiv.org/abs/2506.04614)| [//]: #07/13
|[![Star](https://img.shields.io/github/stars/penghao-wu/GUI_Reflection.svg?style=social&label=Star)](https://github.com/penghao-wu/GUI_Reflection)<br>[GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior](https://arxiv.org/abs/2506.08012) <br> Penghao Wu, Shengnan Ma, Bo Wang, Jiaheng Yu, Lewei Lu, Ziwei Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2506.08012v1/x2.png"> |[Github](https://github.com/penghao-wu/GUI_Reflection) <br> [Paper](https://arxiv.org/abs/2506.08012)| [//]: #07/13
### Data Generation for Agent Training
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/OPPO-PersonalAI/TaskCraft.svg?style=social&label=Star)](https://github.com/OPPO-PersonalAI/TaskCraft)<br>[TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055) <br> Dingfeng Shi, Jingyi Cao, Qianben Chen, Weichen Sun, Weizhen Li, Hongxuan Lu, Fangchen Dong, Tianrui Qin, King Zhu, Minghao Liu, Jian Yang, Ge Zhang, Jiaheng Liu, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou |<img width="1002" alt="image" src="https://arxiv.org/html/2506.10055v2/x3.png"> |[Github](https://github.com/OPPO-PersonalAI/TaskCraft) <br> [Paper](https://arxiv.org/abs/2506.10055)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/sunblaze-ucb/AgentSynth.svg?style=social&label=Star)](https://github.com/sunblaze-ucb/AgentSynth)<br>[AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/abs/2506.14205) <br> Jingxu Xie, Dylan Xu, Xuandong Zhao, Dawn Song |<img width="1002" alt="image" src="figures/AgentSynth.png"> |[Github](https://github.com/sunblaze-ucb/AgentSynth) <br> [Paper](https://arxiv.org/abs/2506.14205)| [//]: #07/13
### Evaluation
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/web-arena-x/webarena.svg?style=social&label=Star)](https://github.com/web-arena-x/webarena)<br>[WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854) <br> Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig |<img width="1002" alt="image" src="https://github.com/web-arena-x/webarena/raw/main/media/overview.png"> |[Github](https://github.com/web-arena-x/webarena) <br> [Paper](https://arxiv.org/abs/2307.13854)| [//]: #07/18
|[![Star](https://img.shields.io/github/stars/openai/simple-evals.svg?style=social&label=Star)](https://github.com/openai/simple-evals)<br>[BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents](https://arxiv.org/abs/2504.12516) <br> Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, Amelia Glaese |<img width="1002" alt="image" src="figures/BrowseComp.png"> |[Github](https://github.com/openai/simple-evals) <br> [Paper](https://arxiv.org/abs/2504.12516)| [//]: #07/18
|[![Star](https://img.shields.io/github/stars/RUCKBReasoning/SpreadsheetBench.svg?style=social&label=Star)](https://github.com/RUCKBReasoning/SpreadsheetBench) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[SpreadsheetBench: Towards Challenging Real World Spreadsheet Manipulation](https://arxiv.org/abs/2406.14991) <br> Zeyao Ma, Bohan Zhang, Jing Zhang, Jifan Yu, Xiaokang Zhang, Xiaohan Zhang, Sijia Luo, Xi Wang, Jie Tang |<img width="1002" alt="image" src="https://arxiv.org/html/2406.14991v2/x2.png"> |[Github](https://github.com/RUCKBReasoning/SpreadsheetBench) <br> [Paper](https://arxiv.org/abs/2406.14991)| [//]: #07/18
|[![Star](https://img.shields.io/github/stars/sierra-research/tau-bench.svg?style=social&label=Star)](https://github.com/sierra-research/tau-bench)<br>[τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains](https://arxiv.org/abs/2406.12045) <br> Shunyu Yao, Noah Shinn, Pedram Razavi, Karthik Narasimhan |<img width="1002" alt="image" src="figures/tau_bench.png"> |[Github](https://github.com/sierra-research/tau-bench) <br> [Paper](https://arxiv.org/abs/2406.12045)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/open-compass/GTA.svg?style=social&label=Star)](https://github.com/open-compass/GTA) [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024-blue)]()<br>[GTA: A Benchmark for General Tool Agents](https://arxiv.org/abs/2407.08713) <br> Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le |<img width="1002" alt="image" src="https://arxiv.org/html/2407.08713v2/x2.png"> |[Github](https://github.com/open-compass/GTA) <br> [Paper](https://arxiv.org/abs/2407.08713)| [//]: #07/17
|[ACEBench: Who Wins the Match Point in Tool Usage?](https://arxiv.org/abs/2501.12851) <br> Chen Chen, Xinlong Hao, Weiwen Liu, Xu Huang, Xingshan Zeng, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Yuefeng Huang, Wulong Liu, Xinzhi Wang, Defu Lian, Baoqun Yin, Yasheng Wang, Wu Liu |<img width="1002" alt="image" src="https://arxiv.org/html/2501.12851v5/x1.png"> |[Paper](https://arxiv.org/abs/2501.12851)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/CaraJ7/MMSearch.svg?style=social&label=Star)](https://github.com/CaraJ7/MMSearch) [![Publish](https://img.shields.io/badge/Conference-ICLR_2025-blue)]()<br>[MMSearch: Benchmarking the Potential of Large Models as Multi-modal Search Engines](https://arxiv.org/abs/2409.12959v2) <br> Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanmin Wu, Jiayi Lei, Pengshuo Qiu, Pan Lu, Zehui Chen, Chaoyou Fu, Guanglu Song, Peng Gao, Yu Liu, Chunyuan Li, Hongsheng Li |<img width="1002" alt="image" src="https://arxiv.org/html/2409.12959v2/x1.png"> |[Github](https://github.com/CaraJ7/MMSearch) <br> [Paper](https://arxiv.org/abs/2409.12959v2)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/osu-nlp-group/mind2web2.svg?style=social&label=Star)](https://github.com/osu-nlp-group/mind2web2)<br>[Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506) <br> Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su |<img width="1002" alt="image" src="https://github.com/OSU-NLP-Group/Mind2Web-2/raw/main/assets/mind2web2_overview.jpg"> |[Github](https://github.com/osu-nlp-group/mind2web2) <br> [Paper](https://arxiv.org/abs/2506.21506)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/metauto-ai/agent-as-a-judge.svg?style=social&label=Star)](https://github.com/metauto-ai/agent-as-a-judge) [![Publish](https://img.shields.io/badge/Conference-ICML_2025-blue)]()<br>[Agent-as-a-Judge: Evaluate Agents with Agents](https://arxiv.org/abs/2410.10934) <br> Mingchen Zhuge, Changsheng Zhao, Dylan Ashley, Wenyi Wang, Dmitrii Khizbullin, Yunyang Xiong, Zechun Liu, Ernie Chang, Raghuraman Krishnamoorthi, Yuandong Tian, Yangyang Shi, Vikas Chandra, Jürgen Schmidhuber |<img width="1002" alt="image" src="https://arxiv.org/html/2410.10934v2/x1.png"> |[Github](https://github.com/metauto-ai/agent-as-a-judge) <br> [Paper](https://arxiv.org/abs/2410.10934)| [//]: #07/14
### Dataset
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/lmarena/search-arena.svg?style=social&label=Star)](https://github.com/lmarena/search-arena)<br>[Search Arena: Analyzing Search-Augmented LLMs](https://arxiv.org/abs/2506.05334) <br> Mihran Miroyan, Tsung-Han Wu, Logan King, Tianle Li, Jiayi Pan, Xinyan Hu, Wei-Lin Chiang, Anastasios N. Angelopoulos, Trevor Darrell, Narges Norouzi, Joseph E. Gonzalez |<img width="1002" alt="image" src="https://arxiv.org/html/2506.05334v1/extracted/6514317/figure/example.png"> |[Github](https://github.com/lmarena/search-arena) <br> [Paper](https://arxiv.org/abs/2506.05334)| [//]: #07/17
### Survey
#### Background
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[Agentic Large Language Models, a survey](https://arxiv.org/abs/2503.23037) <br> Aske Plaat, Max van Duijn, Niki van Stein, Mike Preuss, Peter van der Putten, Kees Joost Batenburg |<img width="1002" alt="image" src="https://arxiv.org/html/2503.23037v2/extracted/6333817/figures/assistant.png"> |[Paper](https://arxiv.org/abs/2503.23037)| [//]: #07/19
|[A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/abs/2308.11432) <br> Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen |<img width="1002" alt="image" src="https://arxiv.org/html/2308.11432v7/x2.png"> |[Paper](https://arxiv.org/abs/2308.11432)| [//]: #07/17
#### Tool
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/jingyi0000/VLM_survey.svg?style=social&label=Star)](https://github.com/jingyi0000/VLM_survey) [![Publish](https://img.shields.io/badge/Conference-TPAMI_2024-blue)]()<br>[Vision-Language Models for Vision Tasks: A Survey](https://arxiv.org/abs/2304.00685) <br> Jingyi Zhang, Jiaxing Huang, Sheng Jin, Shijian Lu |<img width="1002" alt="image" src="https://arxiv.org/html/2304.00685v2/x4.png"> |[Github](https://github.com/jingyi0000/VLM_survey) <br> [Paper](https://arxiv.org/abs/2304.00685)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/quchangle1/LLM-Tool-Survey.svg?style=social&label=Star)](https://github.com/quchangle1/LLM-Tool-Survey) [![Publish](https://img.shields.io/badge/Conference-FCS_2025-blue)]()<br>[Tool Learning with Large Language Models: A Survey](https://arxiv.org/abs/2405.17935v1) <br> Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen |<img width="1002" alt="image" src="https://arxiv.org/html/2405.17935v1/x2.png"> |[Github](https://github.com/quchangle1/LLM-Tool-Survey) <br> [Paper](https://arxiv.org/abs/2405.17935v1)| [//]: #07/14
|[What Are Tools Anyway? A Survey from the Language Model Perspective](https://arxiv.org/abs/2403.15452) <br> Zhiruo Wang, Zhoujun Cheng, Hao Zhu, Daniel Fried, Graham Neubig |<img width="1002" alt="image" src="https://arxiv.org/html/2403.15452v1/x1.png"> |[Paper](https://arxiv.org/abs/2403.15452)| [//]: #07/14
#### GUI
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[![Star](https://img.shields.io/github/stars/vyokky/LLM-Brained-GUI-Agents-Survey.svg?style=social&label=Star)](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey)<br>[Large Language Model-Brained GUI Agents: A Survey](https://arxiv.org/abs/2411.18279) <br> Chaoyun Zhang, Shilin He, Jiaxu Qian, Bowen Li, Liqun Li, Si Qin, Yu Kang, Minghua Ma, Guyue Liu, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang |<img width="1002" alt="image" src="https://arxiv.org/html/2411.18279v12/x2.png"> |[Github](https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey) <br> [Paper](https://arxiv.org/abs/2411.18279)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/zju-real/Awesome-GUI-Agents.svg?style=social&label=Star)](https://github.com/zju-real/Awesome-GUI-Agents)<br>[A Survey on (M)LLM-Based GUI Agents](https://arxiv.org/abs/2504.13865) <br> Fei Tang, Haolei Xu, Hang Zhang, Siqi Chen, Xingyu Wu, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Zeqi Tan, Yuchen Yan, Kaitao Song, Jian Shao, Weiming Lu, Jun Xiao, Yueting Zhuang |<img width="1002" alt="image" src="https://arxiv.org/html/2504.13865v2/x3.png"> |[Github](https://github.com/zju-real/Awesome-GUI-Agents) <br> [Paper](https://arxiv.org/abs/2504.13865)| [//]: #07/19
|[GUI Agents with Foundation Models: A Comprehensive Survey](https://arxiv.org/abs/2411.04890) <br> Shuai Wang, Weiwen Liu, Jingxuan Chen, Yuqi Zhou, Weinan Gan, Xingshan Zeng, Yuhan Che, Shuai Yu, Xinlong Hao, Kun Shao, Bin Wang, Chuhan Wu, Yasheng Wang, Ruiming Tang, Jianye Hao |<img width="1002" alt="image" src="https://arxiv.org/html/2411.04890v2/x2.png"> |[Paper](https://arxiv.org/abs/2411.04890)| [//]: #07/14
### Background
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
| [![Publish](https://img.shields.io/badge/Conference-NeurIPS_2024_Workshop-blue)]()<br>[Agents Thinking Fast and Slow: A Talker-Reasoner Architecture](https://arxiv.org/abs/2410.08328) <br> Konstantina Christakopoulou, Shibl Mourad, Maja Matarić |<img width="1002" alt="image" src="https://arxiv.org/html/2410.08328v1/extracted/5914711/images/agents-talk-extract-react-3.png"> |[Paper](https://arxiv.org/abs/2410.08328)| [//]: #07/17
|[![Star](https://img.shields.io/github/stars/OPPO-PersonalAI/Agent-KB.svg?style=social&label=Star)](https://github.com/OPPO-PersonalAI/Agent-KB)<br>[Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving](https://arxiv.org/abs/2507.06229) <br> Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, Fang Wu, He Zhu, Ge Zhang, Jiaheng Liu, Xingyao Wang, Sirui Hong, Chenglin Wu, Hao Cheng, Chi Wang, Wangchunshu Zhou |<img width="1002" alt="image" src="https://github.com/OPPO-PersonalAI/Agent-KB/raw/master/assets/agent_kb.png"> |[Github](https://github.com/OPPO-PersonalAI/Agent-KB) <br> [Paper](https://arxiv.org/abs/2507.06229)| [//]: #07/14
### Domain-Specific Agents
| Title & Authors | Introduction | Links |
|:--|  :----: | :---:|
|[QUITE: A Query Rewrite System Beyond Rules with LLM Agents](https://arxiv.org/abs/2506.07675) <br> Yuyang Song, Hanxu Yan, Jiale Lao, Yibo Wang, Yufei Li, Yuanchun Zhou, Jianguo Wang, Mingjie Tang |<img width="1002" alt="image" src="https://arxiv.org/html/2506.07675v2/x3.png"> |[Paper](https://arxiv.org/abs/2506.07675)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/AIGeeksGroup/PresentAgent.svg?style=social&label=Star)](https://github.com/AIGeeksGroup/PresentAgent)<br>[PresentAgent: Multimodal Agent for Presentation Video Generation](https://www.arxiv.org/abs/2507.04036) <br> Jingwei Shi, Zeyu Zhang, Biao Wu, Yanjie Liang, Meng Fang, Ling Chen, Yang Zhao |<img width="1002" alt="image" src="https://arxiv.org/html/2507.04036v1/x3.png"> |[Github](https://github.com/AIGeeksGroup/PresentAgent) <br> [Paper](https://www.arxiv.org/abs/2507.04036)| [//]: #07/14
|[![Star](https://img.shields.io/github/stars/innovatingAI/AutoMind.svg?style=social&label=Star)](https://github.com/innovatingAI/AutoMind)<br>[AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/abs/2506.10974) <br> Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Shuofei Qiao, Jintian Zhang, Da Zheng, Huajun Chen, Ningyu Zhang |<img width="1002" alt="image" src="https://github.com/InnovatingAI/AutoMind/raw/main/assets/framework.png"> |[Github](https://github.com/innovatingAI/AutoMind) <br> [Paper](https://arxiv.org/abs/2506.10974)| [//]: #07/14

## Acknowledgement
This repository is inspired by [Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM/) and [Awesome-Efficient-Reasoning-Models
](https://github.com/fscdc/Awesome-Efficient-Reasoning-Models)